{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emacs: -*- mode: python-mode; py-indent-offset: 4; tab-width: 4; indent-tabs-mode: nil -*-\n",
    "# ex: set sts=4 ts=4 sw=4 et:\n",
    "\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import inspect\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from utils import remove_unicode\n",
    "\n",
    "\n",
    "def etext_to_rcsv(in_file, param_file, out_file=None):\n",
    "  \n",
    "    with open(param_file, 'r') as file_object:\n",
    "        param_dict = json.load(file_object)\n",
    "\n",
    "    filename, suffix = os.path.splitext(in_file)\n",
    "    if suffix == '.txt':\n",
    "        # Remove first three lines of exported E-Prime tab-delimited text file.\n",
    "        rem_lines = list(range(3))\n",
    "        delimiter_ = '\\t'\n",
    "    elif suffix == '.csv':\n",
    "        # Remove no lines of comma-delimited csv file.\n",
    "        rem_lines = []\n",
    "        delimiter_ = ','\n",
    "    else:\n",
    "        raise Exception('File not txt or csv: {0}'.format(in_file))\n",
    "\n",
    "    df = pd.read_csv(in_file, skiprows=rem_lines, sep=delimiter_)\n",
    "\n",
    "    header_list = param_dict.get('headers')\n",
    "    df = df[header_list]\n",
    "\n",
    "    if param_dict['rem_nulls']:\n",
    "        df = df.dropna(axis=0, how='all')\n",
    "\n",
    "    if out_file is None:\n",
    "        out_file = filename + '.csv'\n",
    "\n",
    "    df.to_csv(out_file, index=False)\n",
    "    print('Output file successfully created- {0}'.format(out_file))\n",
    "\n",
    "\n",
    "def text_to_csv(text_file, out_file):\n",
    "  \n",
    "    df = _text_to_df(text_file)\n",
    "\n",
    "    df.to_csv(out_file, index=False)\n",
    "    print('Output file successfully created- {0}'.format(out_file))\n",
    "\n",
    "\n",
    "def text_to_rcsv(text_file, edat_file, param_file, out_file):\n",
    "   \n",
    "    with open(param_file, 'r') as file_object:\n",
    "        param_dict = json.load(file_object)\n",
    "\n",
    "    df = _text_to_df(text_file)\n",
    "\n",
    "    # Rename columns\n",
    "    _, edat_suffix = os.path.splitext(edat_file)\n",
    "    replace_dict = param_dict.get('replace_dict')\n",
    "    if replace_dict:\n",
    "        replacements = replace_dict.get(edat_suffix)\n",
    "        df = df.rename(columns=replacements)\n",
    "\n",
    "    # Merge columns\n",
    "    merge_cols = param_dict.get('merge_cols')\n",
    "    for col in list(merge_cols.keys()):\n",
    "        df[col] = df[merge_cols[col]].fillna('').sum(axis=1)\n",
    "\n",
    "    # Drop NaNs based on specific columns\n",
    "    if param_dict.get('rem_nulls', False):\n",
    "        df = df.dropna(subset=param_dict.get('null_cols'), how='all')\n",
    "\n",
    "    # Reduce DataFrame to desired columns\n",
    "    header_list = param_dict.get('headers')\n",
    "    df = df[header_list]\n",
    "\n",
    "    # Write out reduced csv\n",
    "    df.to_csv(out_file, index=False)\n",
    "    print('Output file successfully created- {0}'.format(out_file))\n",
    "\n",
    "\n",
    "def _text_to_df(text_file):\n",
    "    \"\"\"\n",
    "    Convert a raw E-Prime output text file into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Load the text file as a list.\n",
    "    with open(text_file, 'rb') as fo:\n",
    "        text_data = list(fo)\n",
    "\n",
    "    # Remove unicode characters.\n",
    "    filtered_data = [remove_unicode(row.decode('utf-8', 'ignore')) for row in text_data]\n",
    "\n",
    "    # Determine where rows begin and end.\n",
    "    start_index = [i for i, row in enumerate(filtered_data) if row == '*** LogFrame Start ***']\n",
    "    end_index = [i for i, row in enumerate(filtered_data) if row == '*** LogFrame End ***']\n",
    "    if len(start_index) != len(end_index) or start_index[0] >= end_index[0]:\n",
    "        print('Warning: LogFrame Starts and Ends do not match up.',\n",
    "              'Including header metadata just in case.')\n",
    "        # In cases of an experiment crash, the final LogFrame is never written, and the experiment metadata\n",
    "        # (Subject, VersionNumber, etc.) isn't collected by the indices above. We can manually include the\n",
    "        # metadata-containing Header Frame to collect these data from a partial-run crash dump.\n",
    "        start_index = [i for i,row in enumerate(filtered_data) if row == '*** Header Start ***'] + start_index\n",
    "        end_index = [i for i,row in enumerate(filtered_data) if row == '*** Header End ***'] + end_index\n",
    "    n_rows = min(len(start_index), len(end_index))\n",
    "\n",
    "    # Find column headers and remove duplicates.\n",
    "    headers = []\n",
    "    data_by_rows = []\n",
    "    for i in range(n_rows):\n",
    "        one_row = filtered_data[start_index[i]+1:end_index[i]]\n",
    "        data_by_rows.append(one_row)\n",
    "        for col_val in one_row:\n",
    "            split_header_idx = col_val.index(':')\n",
    "            headers.append(col_val[:split_header_idx])\n",
    "\n",
    "    headers = list(OrderedDict.fromkeys(headers))\n",
    "\n",
    "    # Preallocate list of lists composed of NULLs.\n",
    "    data_matrix = np.empty((n_rows, len(headers)), dtype=object)\n",
    "    data_matrix[:] = np.nan\n",
    "\n",
    "    # Fill list of lists with relevant data from data_by_rows and headers.\n",
    "    for i in range(n_rows):\n",
    "        for cell_data in data_by_rows[i]:\n",
    "            split_header_idx = cell_data.index(':')\n",
    "            for k_header, header in enumerate(headers):\n",
    "                if cell_data[:split_header_idx] == header:\n",
    "                    data_matrix[i, k_header] = cell_data[split_header_idx+1:].lstrip()\n",
    "\n",
    "    df = pd.DataFrame(columns=headers, data=data_matrix)\n",
    "\n",
    "    # Columns with one value at the beginning, the end, or end - 1 should be\n",
    "    # filled with that value.\n",
    "    for col in df.columns:\n",
    "        non_nan_idx = np.where(df[col].values == df[col].values)[0]\n",
    "        if len(non_nan_idx) == 1 and non_nan_idx[0] in [0, df.shape[0]-1,\n",
    "                                                        df.shape[0]-2]:\n",
    "            df.loc[:, col] = df.loc[non_nan_idx[0], col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
